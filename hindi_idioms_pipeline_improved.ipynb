{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e865cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to /home/student/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a26ede58",
   "metadata": {},
   "outputs": [],
   "source": [
    "n= 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1b49788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "बिना सोचे-समझे उसने इतना बड़ा निर्णय ले लिया, यह तो अपने पाँव में कुल्हाड़ी मारना है।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_idioms = pd.read_csv(\"hindi_meaning_idioms_csv.csv\")\n",
    "df_idioms\n",
    "\n",
    "idioms = df_idioms['idiom_tokens'].tolist()\n",
    "\n",
    "\n",
    "with open('hindi_text_list_100.txt', 'r', encoding='utf-8') as file:\n",
    "    all_lines = file.readlines()\n",
    "    text = all_lines[n]\n",
    "print(text)\n",
    "\n",
    "hindi_sentences = idioms\n",
    "text_to_match = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "545ff0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest Matched Sentence: अपने पाँव कुल्हाड़ी मार\n",
      "With Line: बिना सोचे-समझे उसने इतना बड़ा निर्णय ले लिया, यह तो अपने पाँव में कुल्हाड़ी मारना है।\n",
      "Levenshtein Distance: 62\n",
      "Context: \n"
     ]
    }
   ],
   "source": [
    "def manual_sentence_tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the input text into sentences.\n",
    "    \n",
    "    Args:\n",
    "    text (str): Input text to tokenize.\n",
    "    \n",
    "    Returns:\n",
    "    list: List of tokenized sentences.\n",
    "    \"\"\"\n",
    "    return re.split(r'(?<!\\d)\\.|\\.\\.\\.|!|\\?|\\n', text)\n",
    "\n",
    "def find_closest_match(hindi_sentences, sentence_to_match):\n",
    "    \"\"\"\n",
    "    Finds the closest match for a given sentence from a list of Hindi sentences\n",
    "    using the Levenshtein distance, while preserving the order of matching words.\n",
    "    \n",
    "    Args:\n",
    "    hindi_sentences (list): List of Hindi sentences.\n",
    "    sentence_to_match (str): Sentence to find the closest match for.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Closest matched sentence and its Levenshtein distance.\n",
    "    \"\"\"\n",
    "    closest_sentence = None\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    sentence_to_match_words = sentence_to_match.split()\n",
    "\n",
    "    for sentence in hindi_sentences:\n",
    "        sentence_words = sentence.split()\n",
    "\n",
    "        # Check for order-preserved matching words\n",
    "        match_indices = [sentence_words.index(word) for word in sentence_to_match_words if word in sentence_words]\n",
    "\n",
    "        if sorted(match_indices) == match_indices and len(match_indices) >= 2:\n",
    "            distance = levenshtein_distance(sentence, sentence_to_match)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_sentence = sentence\n",
    "\n",
    "    return closest_sentence, min_distance\n",
    "\n",
    "def find_closest_matched_sentence(hindi_sentences, sentences_to_match):\n",
    "    \"\"\"\n",
    "    Finds the closest match for each sentence in a list of sentences to match\n",
    "    from a list of Hindi sentences.\n",
    "    \n",
    "    Args:\n",
    "    hindi_sentences (list): List of Hindi sentences.\n",
    "    sentences_to_match (list): List of sentences to find matches for.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Closest matched sentence, original sentence, its Levenshtein distance,\n",
    "           and the previous sentence.\n",
    "    \"\"\"\n",
    "    closest_match = None\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    for i, text_sentence in enumerate(sentences_to_match):\n",
    "        prev_sentence = sentences_to_match[i - 1] if i > 0 else \"\"\n",
    "        closest_sentence, distance = find_closest_match(hindi_sentences, text_sentence)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_match = (closest_sentence, text_sentence, min_distance, prev_sentence)\n",
    "\n",
    "    return closest_match\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    sentences_to_match = manual_sentence_tokenize(text_to_match)\n",
    "\n",
    "    closest_match = find_closest_matched_sentence(hindi_sentences, sentences_to_match)\n",
    "\n",
    "    try:\n",
    "        hindi_sentence, text_sentence, distance, prev_sentence = closest_match\n",
    "        print(f\"Closest Matched Sentence: {hindi_sentence}\")\n",
    "        print(f\"With Line: {text_sentence}\")\n",
    "        print(f\"Levenshtein Distance: {distance}\")\n",
    "        print(f\"Context: {prev_sentence}\")\n",
    "    except TypeError:\n",
    "        print(\"No close match found\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af33b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Sentence: अपने पाँव कुल्हाड़ी मार\n",
      "With Line: बिना सोचे-समझे उसने इतना बड़ा निर्णय ले लिया, यह तो अपने पाँव में कुल्हाड़ी मारना है।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to check if at least two words match\n",
    "def match_sentences(hindi_sentences, sentences_to_match):\n",
    "    matched_sentences = []\n",
    "    for text_sentence in sentences_to_match:\n",
    "        for sentence in hindi_sentences:\n",
    "            # Tokenize the sentences into words (simple split by whitespace)\n",
    "            hindi_words = set(sentence.split())\n",
    "            text_words = set(text_sentence.split())\n",
    "\n",
    "            # Find the intersection of words\n",
    "            common_words = hindi_words.intersection(text_words)\n",
    "\n",
    "            # Check if there are at least 2 common words\n",
    "            if len(common_words) >= 2:\n",
    "                matched_sentences.append((sentence, text_sentence))\n",
    "                break\n",
    "    return matched_sentences\n",
    "\n",
    "# Get the matched sentences\n",
    "matched_sentences = match_sentences(hindi_sentences, sentences_to_match)\n",
    "\n",
    "# Print the results\n",
    "for hindi_sentence, text_sentence in matched_sentences:\n",
    "    print(f\"Matched Sentence: {hindi_sentence}\")\n",
    "    print(f\"With Line: {text_sentence}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68a71714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context To Translate:  उसने उसे के से दिया।\n",
      "He gave it to her from K.\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "words_to_remove = set(hindi_sentence.split())\n",
    "new_sentence= ' '.join(word for word in text_sentence.split() if word not in words_to_remove)\n",
    "context_hindi = \"\"\n",
    "context_hindi = prev_sentence + \" \" +new_sentence\n",
    "print(f\" Context To Translate: {context_hindi}\")\n",
    "\n",
    "english_context = GoogleTranslator(source='hi', target='en').translate(context_hindi)\n",
    "print(english_context)\n",
    "\n",
    "idiom_index = idioms.index(hindi_sentence)\n",
    "print(idiom_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92b50590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['peg,', 'tie']\n"
     ]
    }
   ],
   "source": [
    "keyword_set = []\n",
    "keywords = df_idioms[\"idiom_keywords\"].tolist()\n",
    "keywords_set = keywords[idiom_index]\n",
    "keywords_set = keywords_set.split()\n",
    "print(keywords_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d406516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab9618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
